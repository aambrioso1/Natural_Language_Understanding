# Natural_Language_Understanding

A repository of notes and information related to Natural Language Understanding.   My intention is to focus on large language models and their emerging ability learn from explanations (few-shot prompting).

Here is a set up papers that cover this area:

https://www.gwern.net/docs/ai/gpt/inner-monologue/index

Here is a quote from the first paper on the list, ["Can Language Models learn from explanations in context?"](https://arxiv.org/pdf/2204.02329.pdf),

"A new paradigm has emerged in natural language processing: few-shot prompting of large language models. Such models appear to exhibit some in-context learning abilities, such that they can infer how to perform a new language task few-shot from a few examples of input and output pairs within the modelâ€™s context window, but without training."

Other papers to look at:
https://arxiv.org/abs/2005.14165
https://github.com/google/BIG-bench/
https://aclanthology.org/2021.acl-long.90.pdf
https://arxiv.org/pdf/2205.01068.pdf





